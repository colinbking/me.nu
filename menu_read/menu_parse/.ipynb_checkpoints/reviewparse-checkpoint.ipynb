{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import time as t\n",
    "from lxml import html  \n",
    "import requests\n",
    "import json\n",
    "import numpy as np\n",
    "from timeit import default_timer as timer\n",
    "from itertools import cycle\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cd ~/Documents/GitHub/me.nu/menu_read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "food = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if food:\n",
    "    respage = 'https://www.yelp.com/biz/mala-sichuan-bistro-houston-3'\n",
    "    switch = 'food'\n",
    "    import menu_read.ocr_food as ocr\n",
    "    import menu_read.just_read_food as jr\n",
    "    pid = 'ChIJNc4K5cTCQIYRe9OyIN7DcGE'\n",
    "else:\n",
    "    respage = 'https://www.yelp.com/biz/sharetea-houston-2'\n",
    "    switch = 'tea'\n",
    "    import menu_read.ocr_tea as ocr\n",
    "    import menu_read.just_read_tea as jr\n",
    "    pid = 'ChIJjfzjCM_CQIYRPA546CYaE4A'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OCR FUNCTIONALITY TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install --upgrade google-cloud-vision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current directory is : /Users/michaelsprintson/Documents/GitHub/me.nu/menu_read/menu_parse\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'ocr/wa.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-b5b1fac89bc1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mpic_loc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'ocr/menupictures/pic7.jpg'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtest_file_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'mala7'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mocr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetect_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic_loc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_file_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/GitHub/me.nu/menu_read/ocr_food.py\u001b[0m in \u001b[0;36mdetect_text\u001b[0;34m(path, savepath)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdetect_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msavepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;34m\"\"\"Detects text in the file.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_words\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ocr/wa.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     file1 = io.open(\"ocr/menu_tests/\" + savepath +\n",
      "\u001b[0;32m~/Documents/GitHub/me.nu/menu_read/ocr_food.py\u001b[0m in \u001b[0;36mload_words\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_words\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mword_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mvalid_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mvalid_words\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'ocr/wa.txt'"
     ]
    }
   ],
   "source": [
    "# create dictionary\n",
    "pic_loc = 'ocr/menupictures/pic7.jpg'\n",
    "test_file_name = 'mala7'\n",
    "ocr.detect_text(pic_loc, test_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 32\n",
      "H1 Top Notch Pot the Outlaws 31.95\n",
      "H2 Sauerkraut Fish and Lamb Pot 24.95\n",
      "H3 Country Style Blood Curd Dish 14.95\n",
      "H4 Beef Pot 13.95\n",
      "H5 and Crispy Chicken 12.95\n",
      "H6 Duck Stew 12.95\n",
      "H7 Konjac Beef 12.95\n",
      "H8 Lotus Tofu 11.95\n",
      "H9 Three Pepper Beaten Duck 13.95\n",
      "H10 Tea Smoked Duck 13.95\n",
      "H11 Four Joy Lion Head 12.95\n",
      "H12 Fragrant Ribs 12.95\n",
      "F1 Northern Boiling Fish 20.95\n",
      "F2 Sauerkraut Fish Pot 20.95\n",
      "F3 Chengdu Style Pot Roasted Tilapia 18.95\n",
      "F4 Mala Pot Roasted Tilapia 18.95\n",
      "F5 Bean Curd Tilapia Stew 18.95\n",
      "F7 Pot Roasted Black Bean Tilapia 18.95\n",
      "F12 Steamed Tilapia 18.95\n",
      "F9 Sweet and Sour Crispy Tilapia 18.95\n",
      "F10 Scallion Pot Roasted Tilapia 18.95\n",
      "B1 Water Boiled Beef 13.95\n",
      "B2 Cumin Beef 13.95\n",
      "B3 Black Pepper Beef 13.95\n",
      "B4 Mala Beef Tofu 13.95\n",
      "B5 Mongolian Beef 13.95\n",
      "B6 Crispy Mala Beef 13.95\n",
      "B7 Baby Pepper Black Bean Beef 13.95\n",
      "B8 Baby Pepper and Shredded Beef 13.95\n",
      "B9 Satay Beef 13.95\n",
      "B12 Sauteed Lamb with Veggies 16.95\n",
      "B11 Cumin Lamb 16.95\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'H1 Top Notch Pot the Outlaws': 31.95,\n",
       " 'H2 Sauerkraut Fish and Lamb Pot': 24.95,\n",
       " 'H3 Country Style Blood Curd Dish': 14.95,\n",
       " 'H4 Beef Pot': 13.95,\n",
       " 'H5 and Crispy Chicken': 12.95,\n",
       " 'H6 Duck Stew': 12.95,\n",
       " 'H7 Konjac Beef': 12.95,\n",
       " 'H8 Lotus Tofu': 11.95,\n",
       " 'H9 Three Pepper Beaten Duck': 13.95,\n",
       " 'H10 Tea Smoked Duck': 13.95,\n",
       " 'H11 Four Joy Lion Head': 12.95,\n",
       " 'H12 Fragrant Ribs': 12.95,\n",
       " 'F1 Northern Boiling Fish': 20.95,\n",
       " 'F2 Sauerkraut Fish Pot': 20.95,\n",
       " 'F3 Chengdu Style Pot Roasted Tilapia': 18.95,\n",
       " 'F4 Mala Pot Roasted Tilapia': 18.95,\n",
       " 'F5 Bean Curd Tilapia Stew': 18.95,\n",
       " 'F7 Pot Roasted Black Bean Tilapia': 18.95,\n",
       " 'F12 Steamed Tilapia': 18.95,\n",
       " 'F9 Sweet and Sour Crispy Tilapia': 18.95,\n",
       " 'F10 Scallion Pot Roasted Tilapia': 18.95,\n",
       " 'B1 Water Boiled Beef': 13.95,\n",
       " 'B2 Cumin Beef': 13.95,\n",
       " 'B3 Black Pepper Beef': 13.95,\n",
       " 'B4 Mala Beef Tofu': 13.95,\n",
       " 'B5 Mongolian Beef': 13.95,\n",
       " 'B6 Crispy Mala Beef': 13.95,\n",
       " 'B7 Baby Pepper Black Bean Beef': 13.95,\n",
       " 'B8 Baby Pepper and Shredded Beef': 13.95,\n",
       " 'B9 Satay Beef': 13.95,\n",
       " 'B12 Sauteed Lamb with Veggies': 16.95,\n",
       " 'B11 Cumin Lamb': 16.95}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jr.final_dump(\"ocr/menu_tests/mala7.txt\", \"pref_sample.txt\", True, \"mala7\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORT RESTERAUNT REVIEWS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMPORT YELP REVIEWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "reviews_df=pd.DataFrame()\n",
    "  \n",
    "user_agent = 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_5) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/13.0 Safari/605.1.15'\n",
    "webpage = ''\n",
    "nextpage = 'something'\n",
    "xpath_reviews = '//script[@type=\"application/ld+json\"]/text()'\n",
    "xpath_nextpage = '//link[@rel=\"next\"]'\n",
    "headers = {'User-Agent': user_agent}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if food:\n",
    "    reviewdf = pd.read_json('menu_parse/bigmala')\n",
    "elif not food:\n",
    "    reviewdf = pd.read_json('menu_parse/sharetea')\n",
    "else:\n",
    "    reviewdf = pd.DataFrame()\n",
    "\n",
    "    while len(nextpage) > 0:\n",
    "        #print('1')\n",
    "        page = requests.get(webpage, headers = headers)#,proxies={\"http\": proxy, \"https\": proxy})\n",
    "        print('pagegot','\\r')\n",
    "        parser = html.fromstring(page.content)\n",
    "        reviews = parser.xpath(xpath_reviews)\n",
    "        nextpage = parser.xpath(xpath_nextpage)\n",
    "\n",
    "        if len(nextpage) > 0:\n",
    "            nextlink = nextpage[0].get('href')\n",
    "            print(nextlink, end = '\\r')\n",
    "            webpage = nextlink\n",
    "            y = json.loads(list(reviews)[0])['review']\n",
    "\n",
    "            reviewdict = {y.index(i):i for i in y}\n",
    "\n",
    "            reviewdf = pd.concat([reviewdf,pd.DataFrame(reviewdict).T])\n",
    "            \n",
    "    s = lambda x: list(x.values())[0]\n",
    "    reviewdf['reviewRating'] = reviewdf['reviewRating'].apply(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMPORT GOOGLE REVIEWS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### todo: make place id google maps api modular through api call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import googlemaps\n",
    "from datetime import datetime\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmapsapikey = json.load(open('menu_parse/gmapsapikey.json', 'r'))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = f'https://maps.googleapis.com/maps/api/place/details/json?key={gmapsapikey}&place_id={pid}&fields=name,review'\n",
    "response = requests.get(url, headers=headers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "googlereviewdict = json.loads(response.content.decode('utf-8'))['result']['reviews']\n",
    "googlereviewdict = {googlereviewdict.index(i):i for i in googlereviewdict}\n",
    "\n",
    "googlereviewdf = pd.DataFrame(googlereviewdict).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>reviewRating</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tristan &amp; Ashley Boyd</td>\n",
       "      <td>5</td>\n",
       "      <td>Hubby found Mala Sichuan on Yelp and sent it a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pat Patel</td>\n",
       "      <td>4</td>\n",
       "      <td>Very good traditional Chinese food. We definit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Epiphany Animation Studios</td>\n",
       "      <td>3</td>\n",
       "      <td>It was alright. I think maybe they had an off ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Na Li</td>\n",
       "      <td>4</td>\n",
       "      <td>I come here once a while, it used to one of my...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Russell Monroe</td>\n",
       "      <td>2</td>\n",
       "      <td>This review is for the Finn Hall location, but...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       author reviewRating  \\\n",
       "0       Tristan & Ashley Boyd            5   \n",
       "1                   Pat Patel            4   \n",
       "2  Epiphany Animation Studios            3   \n",
       "3                       Na Li            4   \n",
       "4              Russell Monroe            2   \n",
       "\n",
       "                                         description  \n",
       "0  Hubby found Mala Sichuan on Yelp and sent it a...  \n",
       "1  Very good traditional Chinese food. We definit...  \n",
       "2  It was alright. I think maybe they had an off ...  \n",
       "3  I come here once a while, it used to one of my...  \n",
       "4  This review is for the Finn Hall location, but...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "googlereviewdf = googlereviewdf[['author_name','rating','text']]\n",
    "googlereviewdf.columns = ['author','reviewRating','description']\n",
    "googlereviewdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewdf = pd.concat([reviewdf,googlereviewdf],sort = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewdf = reviewdf.reset_index().drop(['index'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reviewdf['reviewRating'] = reviewdf['reviewRating'].apply(lambda x:x['ratingValue'])\n",
    "reviewdf['description'] = reviewdf['description'].apply(lambda x:x.replace('\\n','').replace('-',' ').lower())\n",
    "reviewdf['description'] = reviewdf['description'].apply(lambda x:' '.join([i for i in x.split(\" \") if len(i)>2]))\n",
    "translator = str.maketrans(string.punctuation, ' '*len(string.punctuation)) #map punctuation to space\n",
    "reviewdf['description'] = reviewdf['description'].apply(lambda x:x.translate(translator)).apply(lambda x: ' '.join(x.split()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRAB MENU ITEMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "menuitems = json.load(open('menuJSON/mala7.json'))\n",
    "if food:\n",
    "    menuitems = [x[3:].strip() for x in list(menuitems.keys())]\n",
    "menitems = [x.lower() for x in menuitems]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RANKING MENU ITEMS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sanity check of menu items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['top notch pot the outlaws',\n",
       " 'sauerkraut fish and lamb pot',\n",
       " 'country style blood curd dish',\n",
       " 'beef pot',\n",
       " 'and crispy chicken',\n",
       " 'duck stew',\n",
       " 'konjac beef',\n",
       " 'lotus tofu',\n",
       " 'three pepper beaten duck',\n",
       " 'tea smoked duck',\n",
       " 'four joy lion head',\n",
       " 'fragrant ribs',\n",
       " 'northern boiling fish',\n",
       " 'sauerkraut fish pot',\n",
       " 'chengdu style pot roasted tilapia',\n",
       " 'mala pot roasted tilapia',\n",
       " 'bean curd tilapia stew',\n",
       " 'pot roasted black bean tilapia',\n",
       " 'steamed tilapia',\n",
       " 'sweet and sour crispy tilapia',\n",
       " 'scallion pot roasted tilapia',\n",
       " 'water boiled beef',\n",
       " 'cumin beef',\n",
       " 'black pepper beef',\n",
       " 'mala beef tofu',\n",
       " 'mongolian beef',\n",
       " 'crispy mala beef',\n",
       " 'baby pepper black bean beef',\n",
       " 'baby pepper and shredded beef',\n",
       " 'satay beef',\n",
       " 'sauteed lamb with veggies',\n",
       " 'cumin lamb']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "menitems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = lambda x: [menitem for menitem in menitems if menitem[:math.floor(0.8*len(menitem))] in x]\n",
    "reviewdf['containedMenuItems'] = reviewdf['description'].apply(search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "menitemstoreviews = {}\n",
    "for menitem in menitems:\n",
    "    menitemstoreviews[menitem] = [{},list(reviewdf[reviewdf['containedMenuItems'].map(lambda d: menitem in d)].index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot4plusreviews = len(reviewdf[reviewdf['reviewRating'] >= 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#total number of 4 plus reviews\n",
    "for item in menitemstoreviews:\n",
    "    #print(item,'------',end = '')\n",
    "    allratings = []\n",
    "    fourpluscounter = 0\n",
    "    twominuscounter = 0\n",
    "    totalrev = len(menitemstoreviews[item][1])\n",
    "    \n",
    "    for rev in menitemstoreviews[item][1]:\n",
    "        curstar = reviewdf.iloc[rev]['reviewRating']\n",
    "        allratings.append(curstar)\n",
    "        if curstar >= 4:\n",
    "            fourpluscounter += 1\n",
    "        elif curstar <= 2:\n",
    "            twominuscounter += 1\n",
    "    if not totalrev == 0:\n",
    "        menitemstoreviews[item][0]['extremerev'] = (fourpluscounter - twominuscounter) / (2 * totalrev)\n",
    "    else:\n",
    "        menitemstoreviews[item][0]['extremerev'] = 0\n",
    "    menitemstoreviews[item][0]['percentageoftotalreviews'] = 8.5 * (fourpluscounter) / tot4plusreviews\n",
    "        \n",
    "    if not len(allratings) == 0:\n",
    "        menitemstoreviews[item][0]['avgrev'] = sum(allratings)/(5 * len(allratings))\n",
    "        #print('av rating',sum(allratings)/len(allratings))\n",
    "    else:\n",
    "        menitemstoreviews[item][0]['avgrev'] = 0\n",
    "        #print('no reviews')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "itemratings = pd.DataFrame(menitemstoreviews).T\n",
    "itemratings.columns = ['ratings','indexes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "itemratings['totalscore'] = itemratings['ratings'].apply(lambda x: sum(x.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "water boiled beef                    2.678521\n",
       "cumin beef                           2.092424\n",
       "and crispy chicken                   1.673229\n",
       "cumin lamb                           1.621688\n",
       "mala pot roasted tilapia             1.574015\n",
       "three pepper beaten duck             1.565230\n",
       "steamed tilapia                      1.543966\n",
       "chengdu style pot roasted tilapia    1.529310\n",
       "mongolian beef                       1.525172\n",
       "black pepper beef                    1.517241\n",
       "sauerkraut fish pot                  1.514655\n",
       "satay beef                           1.514655\n",
       "baby pepper and shredded beef        1.514655\n",
       "sweet and sour crispy tilapia        1.514655\n",
       "four joy lion head                   1.477299\n",
       "crispy mala beef                     1.472947\n",
       "tea smoked duck                      1.465405\n",
       "top notch pot the outlaws            1.458621\n",
       "northern boiling fish                1.429310\n",
       "mala beef tofu                       1.413218\n",
       "country style blood curd dish        1.329310\n",
       "fragrant ribs                        1.268966\n",
       "lotus tofu                           1.168966\n",
       "duck stew                            0.929310\n",
       "beef pot                             0.858621\n",
       "baby pepper black bean beef          0.714655\n",
       "sauteed lamb with veggies            0.000000\n",
       "bean curd tilapia stew               0.000000\n",
       "pot roasted black bean tilapia       0.000000\n",
       "scallion pot roasted tilapia         0.000000\n",
       "konjac beef                          0.000000\n",
       "sauerkraut fish and lamb pot         0.000000\n",
       "Name: totalscore, dtype: float64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itemratings['totalscore'].sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WIP / TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# itemratings.loc['water boiled beef']['ratings']\n",
    "\n",
    "# reviewdf[reviewdf['description'].map(lambda d: 'okinawa pearl milk tea' in d)]\n",
    "\n",
    "\n",
    "\n",
    "# reviewdf.iloc[548]['description']\n",
    "\n",
    "\n",
    "\n",
    "# pd.DataFrame(menitemstoreviews).T\n",
    "\n",
    "# reviewdf[reviewdf['author']=='Tristan & Ashley Boyd']\n",
    "\n",
    "# reviewdf.iloc[473]['description']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# #reviewdf.to_json('bigmala')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# USER PREFERENCES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## scrape wikipedia for chinese foods (only run once, save results as JSON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "wikipage = 'https://en.wikipedia.org/wiki/List_of_Chinese_dishes'\n",
    "wikipage = requests.get(wikipage).text\n",
    "wikidf = pd.DataFrame()\n",
    "\n",
    "soup = BeautifulSoup(wikipage)\n",
    "\n",
    "my_tables = soup.findAll('table',{'class':'wikitable'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [],
   "source": [
    "chinesefoods = []\n",
    "for table in my_tables:\n",
    "    alla = list(table.findAll('a'))\n",
    "    chinesefoods = chinesefoods +[x for x in[alla[i].get('title') for i in range(len(alla))] if type(x) == str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "allfoods = list(set([w for s in wn.synset('food.n.02').closure(lambda s:s.hyponyms()) for w in s.lemma_names()])) + chinesefoods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1721"
      ]
     },
     "execution_count": 520,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(allfoods)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## food preferences by users reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'allfoods' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-69-892d4989fc39>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msearch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfood\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfood\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mallfoods\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mfood\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0muserreviewdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'containedFood='\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muserreviewdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'description'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[1;32m   3589\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3590\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3591\u001b[0;31m                 \u001b[0mmapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3592\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3593\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-69-892d4989fc39>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msearch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfood\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfood\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mallfoods\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mfood\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0muserreviewdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'containedFood='\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muserreviewdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'description'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'allfoods' is not defined"
     ]
    }
   ],
   "source": [
    "search = lambda x: [food for food in allfoods if food in x]\n",
    "\n",
    "userreviewdf['containedFood='] = userreviewdf['description'].apply(search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [],
   "source": [
    "food = [x.lower() for x in food]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Notch Pot the Outlaws\n",
      "Sauerkraut Fish and Lamb Pot\n",
      "y fish\n",
      "y lamb\n",
      "Country Style Blood Curd Dish\n",
      "Devourable Beef Pot\n",
      "y beef\n",
      "and Crispy Chicken\n",
      "y chicken\n",
      "Duck Stew\n",
      "y duck\n",
      "Konjac Beef\n",
      "y beef\n",
      "Lotus Tofu\n",
      "Three Pepper Beaten Duck\n",
      "y pepper\n",
      "y duck\n",
      "Tea Smoked Duck\n",
      "y duck\n",
      "Four Joy Lion Head\n",
      "Fragrant Ribs\n",
      "Northern Boiling Fish\n",
      "y fish\n",
      "Sauerkraut Fish Pot\n",
      "y fish\n",
      "Chengdu Style Pot Roasted Tilapia\n",
      "Mala Pot Roasted Tilapia\n",
      "Bean Curd Tilapia Stew\n",
      "y bean\n",
      "Pot Roasted Black Bean Tilapia\n",
      "y bean\n",
      "Steamed Tilapia\n",
      "Sweet and Sour Crispy Tilapia\n",
      "Scallion Pot Roasted Tilapia\n",
      "y scallion\n",
      "Water Boiled Beef\n",
      "y beef\n",
      "Cumin Beef\n",
      "y beef\n",
      "Black Pepper Beef\n",
      "y pepper\n",
      "y beef\n",
      "Mala Beef Tofu\n",
      "y beef\n",
      "Mongolian Beef\n",
      "y beef\n",
      "Baby Pepper Black Bean Beef\n",
      "y pepper\n",
      "y bean\n",
      "y beef\n",
      "Baby Pepper and Shredded Beef\n",
      "y pepper\n",
      "y beef\n",
      "Satay Beef\n",
      "y beef\n",
      "Sauteed Lamb with Veggies\n",
      "y lamb\n",
      "Cumin Lamb\n",
      "y lamb\n"
     ]
    }
   ],
   "source": [
    "for i in menuitems:\n",
    "    test = i.split(\" \")\n",
    "    test = [x.lower() for x in test]\n",
    "    print(i)\n",
    "    for j in test:\n",
    "        if j in food:\n",
    "            print ('y',j)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORT USER REVIEWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grabfullreviws(ureviews):\n",
    "    fullreviews = []\n",
    "    curreview = ''\n",
    "    for i in range(len(ureviews)):\n",
    "        #print('\\n')\n",
    "        if not (i == len(ureviews)-1):\n",
    "            if not type(ureviews[i]) == str:\n",
    "                #print('not a review',ureviews[i],type(ureviews[i]))\n",
    "                pass\n",
    "            elif not type(ureviews[i+1]) == str:\n",
    "                #print('middle of a review',ureviews[i],type(ureviews[i]))\n",
    "                curreview = curreview + ureviews[i]\n",
    "            elif type(ureviews[i+1]) == str:\n",
    "                #print('end of a review',ureviews[i],type(ureviews[i]))\n",
    "                curreview = curreview + ureviews[i]\n",
    "                fullreviews.append(curreview)\n",
    "                curreview = ''\n",
    "        else:\n",
    "            curreview = curreview + ureviews[i]\n",
    "            fullreviews.append(curreview)\n",
    "    return fullreviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<Element a at 0x11cfc7170>]\n",
      "[<Element a at 0x11cfc6590>]\n",
      "[<Element a at 0x11cfc88f0>]\n",
      "[<Element a at 0x11cfc9050>]\n",
      "[<Element a at 0x11cfc8ef0>]\n"
     ]
    }
   ],
   "source": [
    "unextpage = 'something'\n",
    "userpage = 'https://www.yelp.com/user_details_reviews_self?rec_pagestart=0&userid=2fKJeKlPi9le_ta7DPVW_A'\n",
    "userreviewdf = pd.DataFrame()\n",
    "\n",
    "upath_reviews = '//p[@lang=\"en\"]//node()'\n",
    "upath_nextpage = '//a[@class=\"u-decoration-none next pagination-links_anchor\"]'\n",
    "upath_starrating = '//div[@class=\"biz-rating__stars\"]//div'\n",
    "\n",
    "while len(unextpage) > 0:\n",
    "\n",
    "    userpage = requests.get(userpage, headers = headers)#,proxies={\"http\": proxy, \"https\": proxy})\n",
    "    \n",
    "    uparser = html.fromstring(userpage.content)\n",
    "\n",
    "    ureviews = uparser.xpath(upath_reviews)\n",
    "\n",
    "    unextpage = uparser.xpath(upath_nextpage)\n",
    "    \n",
    "    if len(unextpage) > 0:\n",
    "        print(unextpage)\n",
    "        userpage = unextpage[0].get('href')\n",
    "    ustarratingpath = uparser.xpath(upath_starrating)\n",
    "\n",
    "    ureviews = [str(i) if not \"Element br\" in str(i) else 0 for i in ureviews ]\n",
    "\n",
    "    ufullreviews = grabfullreviws(ureviews)\n",
    "\n",
    "    fullstars = [i.get('title') for i in ustarratingpath]\n",
    "\n",
    "    userreviewdf = pd.concat([userreviewdf,pd.DataFrame(list(zip(fullstars,ufullreviews)))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "userreviewdf.columns = ['rating','description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0 star rating</td>\n",
       "      <td>Leave a yelp review for free boba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0 star rating</td>\n",
       "      <td>TL;DR: An affordable apartment complex with gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0 star rating</td>\n",
       "      <td>TL;DR: legit, authentic hand pulled noodles. D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0 star rating</td>\n",
       "      <td>Best Asian bakery in Houston, hands down. I've...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0 star rating</td>\n",
       "      <td>This review is for the bakery. Listen, you sho...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            rating                                        description\n",
       "0  4.0 star rating                  Leave a yelp review for free boba\n",
       "1  5.0 star rating  TL;DR: An affordable apartment complex with gr...\n",
       "2  5.0 star rating  TL;DR: legit, authentic hand pulled noodles. D...\n",
       "3  5.0 star rating  Best Asian bakery in Houston, hands down. I've...\n",
       "4  5.0 star rating  This review is for the bakery. Listen, you sho..."
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "userreviewdf.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
